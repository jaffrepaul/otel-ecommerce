# OpenTelemetry Collector Configuration

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 10s
    send_batch_size: 100
    send_batch_max_size: 1000

  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  resource:
    attributes:
      - key: deployment.environment
        value: ${env:DEPLOYMENT_ENV}
        action: upsert
      - key: collector.version
        value: "1.0.0"
        action: insert

  # Uncomment to filter spans:
  # filter:
  #   traces:
  #     span:
  #       - 'attributes["http.target"] == "/health"'

  # Uncomment for tail sampling:
  # tail_sampling:
  #   decision_wait: 10s
  #   num_traces: 100
  #   policies:
  #     - name: error-traces
  #       type: status_code
  #       status_code: {status_codes: [ERROR]}
  #     - name: slow-traces
  #       type: latency
  #       latency: {threshold_ms: 1000}

exporters:
  otlphttp/sentry:
    endpoint: ${env:OTEL_EXPORTER_OTLP_ENDPOINT}
    headers:
      x-sentry-auth: ${env:SENTRY_AUTH_HEADER}
    compression: gzip
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # Uncomment for debug output:
  # debug:
  #   verbosity: detailed

  # Uncomment to add another backend:
  # otlp/jaeger:
  #   endpoint: jaeger:4317
  #   tls:
  #     insecure: true

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  pprof:
    endpoint: 0.0.0.0:1777
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [otlphttp/sentry]
    
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [otlphttp/sentry]

  telemetry:
    logs:
      level: info
    metrics:
      address: 0.0.0.0:8888

